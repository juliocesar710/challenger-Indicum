# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mmdZBjpynClj6FtoHO20xt32jTc2DLzo
"""

import os

os.listdir('/content/')

import pandas as pd

df = pd.read_csv('/content/teste_indicium_precificacao.csv')

df.head()

print(f"Formato do dataset: {df.shape}")

df.info()


df.describe()

df.isnull().sum()

df['nome'].fillna("Sem Nome", inplace=True)
df['host_name'].fillna("Desconhecido", inplace=True)
df['ultima_review'].fillna("Sem avaliaÃ§Ã£o", inplace=True)

df['reviews_por_mes'].fillna(0, inplace=True)

print(df.isnull().sum())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,5))


sns.boxplot(x=df['price'])

plt.title("DistribuiÃ§Ã£o dos PreÃ§os")
plt.xlabel("PreÃ§o (USD)")
plt.show()

plt.figure(figsize=(10,5))
sns.barplot(x=df['room_type'], y=df['price'], estimator=lambda x: x.mean(), ci=None)

plt.title("PreÃ§o MÃ©dio por Tipo de AcomodaÃ§Ã£o")
plt.ylabel("PreÃ§o MÃ©dio (USD)")
plt.xlabel("Tipo de AcomodaÃ§Ã£o")
plt.show()

plt.figure(figsize=(12,6))
sns.countplot(y=df['bairro_group'], order=df['bairro_group'].value_counts().index)

plt.title("NÃºmero de Listagens por Bairro")
plt.xlabel("Quantidade")
plt.ylabel("Bairro")
plt.show()

import numpy as np


df_numeric = df.select_dtypes(include=[np.number])

plt.figure(figsize=(10,6))
sns.heatmap(df_numeric.corr(), annot=True, cmap='coolwarm', fmt=".2f")

plt.title("CorrelaÃ§Ã£o entre as VariÃ¡veis NumÃ©ricas")
plt.show()

bairro_stats = df.groupby('bairro')['price'].agg(['mean', 'count']).reset_index()

bairro_stats = bairro_stats[bairro_stats['count'] >= 100]

bairro_stats['invest_score'] = bairro_stats['mean'] * bairro_stats['count']

top_invest_bairros = bairro_stats.nlargest(10, 'invest_score')

plt.figure(figsize=(12, 6))
sns.barplot(data=top_invest_bairros, x='mean', y='bairro', palette='viridis')

plt.xlabel("PreÃ§o MÃ©dio ($)")
plt.ylabel("Bairro")
plt.title("Top 10 Bairros Mais Indicados para Investimento")


plt.show()

import matplotlib.pyplot as plt
import seaborn as sns


sns.set(style="whitegrid")


plt.figure(figsize=(10, 5))
sns.scatterplot(x=df["minimo_noites"], y=df["price"], alpha=0.5)
plt.xlim(0, 30)
plt.ylim(0, 500)
plt.xlabel("NÃºmero MÃ­nimo de Noites")
plt.ylabel("PreÃ§o (USD)")
plt.title("RelaÃ§Ã£o entre PreÃ§o e NÃºmero MÃ­nimo de Noites")
plt.show()


plt.figure(figsize=(10, 5))
sns.scatterplot(x=df["disponibilidade_365"], y=df["price"], alpha=0.5)
plt.xlabel("Disponibilidade ao longo do ano (dias)")
plt.ylabel("PreÃ§o (USD)")
plt.title("RelaÃ§Ã£o entre PreÃ§o e Disponibilidade Anual")
plt.show()


plt.figure(figsize=(8,6))
sns.heatmap(df[["price", "minimo_noites", "disponibilidade_365"]].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("CorrelaÃ§Ã£o entre PreÃ§o, NÃºmero MÃ­nimo de Noites e Disponibilidade")
plt.show()

from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords


nltk.download('stopwords')


stopwords_personalizadas = set(stopwords.words("english") + stopwords.words("portuguese") +
                               ["bedroom", "apt", "apartment", "quarto", "casa", "room", "in", "the", "with", "2", "1", "of", "i", "1br"])


def contar_palavras(df, coluna="nome"):
    palavras = " ".join(df[coluna].dropna()).lower().split()
    palavras_filtradas = [p for p in palavras if p not in stopwords_personalizadas and len(p) > 2]
    contagem = Counter(palavras_filtradas)
    return contagem.most_common(20)

top_listings = df[df["price"] > df["price"].quantile(0.75)]
cheap_listings = df[df["price"] < df["price"].quantile(0.25)]


top_words = contar_palavras(top_listings)
cheap_words = contar_palavras(cheap_listings)


palavras_df = pd.DataFrame(top_words, columns=["Palavra", "FrequÃªncia - AnÃºncios Caros"])
palavras_df["FrequÃªncia - AnÃºncios Baratos"] = [dict(cheap_words).get(p, 0) for p in palavras_df["Palavra"]]


plt.figure(figsize=(12, 6))
sns.barplot(x="Palavra", y="FrequÃªncia - AnÃºncios Caros", data=palavras_df, color="blue", label="Caros")
sns.barplot(x="Palavra", y="FrequÃªncia - AnÃºncios Baratos", data=palavras_df, color="red", alpha=0.6, label="Baratos")
plt.xticks(rotation=45)
plt.legend()
plt.title("Palavras mais comuns em anÃºncios caros vs. baratos (filtradas)")
plt.show()


top_text = " ".join([p for nome in top_listings["nome"].dropna()
                     for p in nome.lower().split()
                     if p not in stopwords_personalizadas and len(p) > 2])
wordcloud = WordCloud(width=800, height=400, background_color="white").generate(top_text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.title("Nuvem de Palavras: AnÃºncios Mais Caros (filtradas)")
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LinearRegression
import numpy as np


df = pd.read_csv("/content/teste_indicium_precificacao.csv")


colunas_remover = ['id', 'nome', 'host_id', 'host_name', 'ultima_review']
df = df.drop(columns=colunas_remover)


categoricas = ['bairro', 'bairro_group', 'room_type']
numericas = ['minimo_noites', 'numero_de_reviews', 'reviews_por_mes',
             'calculado_host_listings_count', 'disponibilidade_365', 'latitude', 'longitude']


df[numericas] = df[numericas].fillna(df[numericas].mean())

df[categoricas] = df[categoricas].fillna(df[categoricas].mode().iloc[0])





X = df.drop(columns=['price'])
y = df['price']


encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
scaler = StandardScaler()

X_categ_encoded = encoder.fit_transform(X[categoricas])
X_numerico_scaled = scaler.fit_transform(X[numericas])


X_categ_encoded = pd.DataFrame(X_categ_encoded, columns=encoder.get_feature_names_out(categoricas))
X_numerico_scaled = pd.DataFrame(X_numerico_scaled, columns=numericas)


X_final = pd.concat([X_categ_encoded, X_numerico_scaled], axis=1)


X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)


modelo = LinearRegression()
modelo.fit(X_train, y_train)


def transformar_dados(novo_apartamento):

    df_novo = pd.DataFrame([novo_apartamento])

    df_categ = encoder.transform(df_novo[categoricas])
    df_categ = pd.DataFrame(df_categ, columns=encoder.get_feature_names_out(categoricas))

    df_numerico = scaler.transform(df_novo[numericas])
    df_numerico = pd.DataFrame(df_numerico, columns=numericas)


    df_final = pd.concat([df_categ, df_numerico], axis=1)

    return df_final


novo_apartamento = {
    'bairro': 'Midtown',
    'bairro_group': 'Manhattan',
    'room_type': 'Entire home/apt',
    'minimo_noites': 1,
    'numero_de_reviews': 45,
    'reviews_por_mes': 0.38,
    'calculado_host_listings_count': 2,
    'disponibilidade_365': 355,
    'latitude': 40.75362,
    'longitude': -73.98377
}

novo_apartamento_transformado = transformar_dados(novo_apartamento)


preco_estimado = modelo.predict(novo_apartamento_transformado)



novo_apartamento['preco_estimado'] = round(preco_estimado[0], 2)

df_apartamento = pd.DataFrame([novo_apartamento])

print("\nðŸ“Œ InformaÃ§Ãµes do Apartamento:")
for chave, valor in novo_apartamento.items():
    print(f"{chave}: {valor}")

import joblib

joblib.dump(modelo, "modelo1.pkl")